{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "\"\"\"\n",
    "This file is implementing the vanilla LSTM.\n",
    "The test set used are the 31 days of December of a single time-serie of the 261 time-series with measurements of the full year 2017.\n",
    "Missing days are estimated.\n",
    "Naive basemodels that are used are the mean forecast and the MAPE-minimization.\n",
    "Evaluation metrics used: MSE, RMSE, NRMSE, MAE\n",
    "####################################################\n",
    "\n",
    "calculate the MSE on the total test set and for each day of the week.\n",
    "Should normalize history and temperature with min max\n",
    "Rest: weekday, time, holiday use one hot encoder\n",
    "Stack different LSTM blocks --> hidden nodes serve as inputs for next LSTM's\n",
    "Use finally a fully connected layer to generate an output\n",
    "Use different learning rules: adam!!, stochastic gradient descent, Adagrad, Adadelta and RMSProp\n",
    "Adam has parameters: learning rate, momentum and decay\n",
    "play with mini batches\n",
    "\n",
    "Inputs:\n",
    "1. history ok\n",
    "2. temp ok\n",
    "3. day week ok\n",
    "4. time ok\n",
    "5. holiday\n",
    "6. (previous week future lag)\n",
    "7. previous week error history lag --> how good are you following previous week\n",
    "just the difference between the values\n",
    "8. previous weeks load at the same moment in time and the temperatures of these days\n",
    "\"\"\"\n"
   ],
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\nThis file is implementing the vanilla LSTM.\\nThe test set used are the 31 days of December of a single time-serie of the 261 time-series with measurements of the full year 2017.\\nMissing days are estimated.\\nNaive basemodels that are used are the mean forecast and the MAPE-minimization.\\nEvaluation metrics used: MSE, RMSE, NRMSE, MAE\\n####################################################\\n\\ncalculate the MSE on the total test set and for each day of the week.\\nShould normalize history and temperature with min max\\nRest: weekday, time, holiday use one hot encoder\\nStack different LSTM blocks --> hidden nodes serve as inputs for next LSTM's\\nUse finally a fully connected layer to generate an output\\nUse different learning rules: adam!!, stochastic gradient descent, Adagrad, Adadelta and RMSProp\\nAdam has parameters: learning rate, momentum and decay\\nplay with mini batches\\n\\nInputs:\\n1. history ok\\n2. temp ok\\n3. day week ok\\n4. time ok\\n5. holiday\\n6. (previous week future lag)\\n7. previous week error history lag --> how good are you following previous week\\njust the difference between the values\\n8. previous weeks load at the same moment in time and the temperatures of these days\\n\""
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd # pandas\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import casadi as ca\n",
    "from Test_basemodel_functions import *\n",
    "\n",
    "\n",
    "plt.rc('axes', linewidth=2)\n",
    "plt.rc('axes', labelsize= 16)\n",
    "plt.rc('axes',titlesize = 18)\n",
    "plt.rc('legend',fontsize=14)\n",
    "plt.rc('xtick', labelsize=16)\n",
    "plt.rc('ytick', labelsize=16)\n",
    "plt.rc('figure',figsize=(10,8))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "# importing the data\n",
    "fullYeardata = pd.read_csv(\"D:\\Onedrive\\Leuven\\Final project\\data\\Forecasting_writtendata\\FullYear.csv\",index_col= \"date\",parse_dates= True)\n",
    "av_temperature = pd.read_csv(\"D:\\Onedrive\\Leuven\\Final project\\data\\weather-avg.csv\",index_col='meter_id')\n",
    "av_temperature = av_temperature.transpose()\n",
    "av_temperature.index = pd.to_datetime(av_temperature.index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "name = fullYeardata.columns[1]\n",
    "TS = fullYeardata[name]\n",
    "temperature = av_temperature[name]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "# subsitute the missing values by prev week < prev day < mean of all the values at that time of the day (rarely used)\n",
    "# this function changes the input!\n",
    "def substitute_missing_values(TS: pd.Series):\n",
    "    for date in TS.index:\n",
    "        if np.isnan(TS[date]):\n",
    "            prev_week =  date + dt.timedelta(days=-7)\n",
    "            prev_day = date + dt.timedelta(days=-1)\n",
    "            if not np.isnan(TS[prev_week]):\n",
    "                TS[date] = TS[prev_week]\n",
    "\n",
    "            elif not np.isnan(TS[prev_day]):\n",
    "                TS[date] = TS[prev_day]\n",
    "\n",
    "            else:\n",
    "                temp = TS[TS.index.hour == date.hour]\n",
    "                data = temp[temp.index.minute == date.minute]\n",
    "                TS[date] = data.mean()\n",
    "    print(\"amount of missing values: %s. \\n\"%TS.isnull().sum())\n",
    "    return TS\n",
    "\n",
    "def substitute_missing_values_temperature(TS: pd.Series):\n",
    "    for date in TS.index:\n",
    "        if np.isnan(TS[date]):\n",
    "            prev_day = date + dt.timedelta(days=-1)\n",
    "            next_day = date + dt.timedelta(days=+1)\n",
    "\n",
    "            if not np.isnan(TS[prev_day]):\n",
    "                TS[date] = TS[prev_day]\n",
    "\n",
    "            elif not np.isnan(TS[next_day]):\n",
    "                TS[date] = TS[next_day]\n",
    "\n",
    "            else:\n",
    "                TS[date] = TS.mean()\n",
    "    print(\"amount of missing values: %s. \\n\" % TS.isnull().sum())\n",
    "    return TS\n",
    "\n",
    "def norm(serie: pd.Series):\n",
    "    values = serie.values\n",
    "    l = len(values)\n",
    "    values = values.reshape((l, 1))\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(values)\n",
    "    norm_serie = scaler.transform(values)\n",
    "    norm_serie = norm_serie.squeeze()\n",
    "    norm_serie = pd.Series(data=norm_serie,index=serie.index)\n",
    "    return norm_serie,scaler\n",
    "\n",
    "# be aware that there are minor calculations rounding errors when transformed back!\n",
    "def norm_inverse(serie: pd.Series, scaler):\n",
    "    values = serie.values\n",
    "    l = len(values)\n",
    "    values = values.reshape((l, 1))\n",
    "    norm_serie = scaler.inverse_transform(values)\n",
    "    norm_serie = norm_serie.squeeze()\n",
    "    norm_serie = pd.Series(data=norm_serie,index=serie.index)\n",
    "    return norm_serie\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of missing values: 0. \n",
      "\n",
      "amount of missing values: 0. \n",
      "\n",
      "amount of missing values: 0. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# all the training dates are present, dates from the test set can be missing.\n",
    "\n",
    "# normalize the data --> min/max method (when using a single time serie)\n",
    "temperature_norm,scaler_temperature = norm(temperature)\n",
    "temperature_norm = substitute_missing_values_temperature(temperature_norm)\n",
    "TS_norm,scaler_history = norm(TS)\n",
    "\n",
    "temp = TS_norm[TS_norm.index.month != 12]\n",
    "test = TS_norm[TS_norm.index.month == 12]\n",
    "# remove from the test set all the days that contain nan values -> only estimate real days\n",
    "# training = TS_norm[0:336]\n",
    "# validation = TS_norm[336:384]\n",
    "# test = TS_norm[384:528]\n",
    "test.dropna(inplace=True)\n",
    "# substitute the missing values\n",
    "temp = substitute_missing_values(temp)\n",
    "training = temp[temp.index.month != 11]\n",
    "validation = temp[temp.index.month == 11]\n",
    "TS_norm_full = substitute_missing_values(TS_norm.copy(deep=True))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "def get_av_temp(time_stamp: pd.Timestamp,temperature: pd.Series)-> float:\n",
    "    return temperature[temperature.index.dayofyear == time_stamp.dayofyear]\n",
    "\n",
    "def get_weekday(time_stamp: pd.Timestamp)-> int:\n",
    "    return time_stamp.weekday()\n",
    "\n",
    "def get_daytime(time_stamp: pd.Timestamp):\n",
    "    value = time_stamp.hour*2\n",
    "    if time_stamp.minute == 30:\n",
    "        value = value + 1\n",
    "    return value\n",
    "\n",
    "def is_holiday(time_stamp: pd.Timestamp, holidays: pd.DatetimeIndex)->bool:\n",
    "    return any(time_stamp.dayofyear == holidays.dayofyear)\n",
    "\n",
    "\n",
    "# forecast one time stamp at the time --> for loop to forecast the 48 time stamps\n",
    "def input_output_LSTM(training, temperature_norm, lag_value: int):\n",
    "    holidays = EnglandAndWalesHolidayCalendar().holidays(start=pd.Timestamp('2017-01-01'),end=pd.Timestamp('2017-12-31'))\n",
    "    amount_forecasts = len(training) - lag_value\n",
    "    amount_features = 1+1+7+48+2\n",
    "    X = np.zeros((amount_forecasts,lag_value,amount_features))\n",
    "    y = np.zeros((amount_forecasts,1))\n",
    "\n",
    "    for sample_id in np.arange(0,amount_forecasts):\n",
    "\n",
    "        history = training.values[sample_id:lag_value + sample_id]\n",
    "        y[sample_id] = training.values[lag_value + sample_id]\n",
    "        X[sample_id,:,0] = history\n",
    "        all_time_stamps = training.index[sample_id:lag_value + sample_id]\n",
    "        for lag_value_index in np.arange(0,lag_value): # goes from old to new\n",
    "            time_stamp = all_time_stamps[lag_value_index]\n",
    "\n",
    "            temperature_feed = get_av_temp(time_stamp,temperature_norm)\n",
    "            X[sample_id,lag_value_index,1] = temperature_feed\n",
    "\n",
    "            weekday = np.zeros(7)\n",
    "            day = get_weekday(time_stamp) # 0 - 6\n",
    "            weekday[day] = 1\n",
    "            X[sample_id,lag_value_index,2:9] = weekday\n",
    "\n",
    "            time = np.zeros(48)\n",
    "            time_of_day = get_daytime(time_stamp) # 0 - 47\n",
    "            time[time_of_day] = 1\n",
    "            X[sample_id,lag_value_index,9:57] = time\n",
    "\n",
    "            holiday = np.zeros(2)\n",
    "            hol = is_holiday(time_stamp,holidays) # [no, yes]\n",
    "            if hol:\n",
    "                holiday[1] = 1\n",
    "            else:\n",
    "                holiday[0] = 1\n",
    "            X[sample_id,lag_value_index,57:59] = holiday\n",
    "\n",
    "\n",
    "    return X,y\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "from keras.layers import Dense,  LSTM,Embedding\n",
    "from keras.models import Sequential, save_model, load_model\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint, History\n",
    "\n",
    "path_checkpoint = \"model_checkpoint.h5\"\n",
    "modelckpt_callback = ModelCheckpoint(monitor=\"val_loss\",filepath=path_checkpoint,verbose=1,save_weights_only=True,save_best_only=True)\n",
    "def build_model(training: pd.Series,validation: pd.Series, temperature_norm: pd.Series, lag_value: int,nb_epoch: int = 1, regularization_parameter: float = 0.01,batch_size_para: int = 32,verbose_para: int = 1, save: bool = False):\n",
    "    history = History()\n",
    "    X,y = input_output_LSTM(training, temperature_norm, lag_value)\n",
    "    X_val,y_val = input_output_LSTM(validation, temperature_norm, lag_value)\n",
    "    regularizers.l2(l=regularization_parameter)\n",
    "    model = Sequential()\n",
    "    # no initial state is given --> hidden state are tensors filled with zeros\n",
    "    # dropout=None,recurrent_dropout=None\n",
    "    model.add(LSTM(units=20,activation='tanh',input_shape=(X.shape[1],X.shape[2])))\n",
    "    model.add(Dense(units=20,activation='relu',kernel_regularizer='l2'))\n",
    "    # model.add(Dropout(0.10))\n",
    "    model.add(Dense(units=y.shape[1],activation='relu',kernel_regularizer='l2'))\n",
    "    model.compile(optimizer='adam',loss='mse')\n",
    "    early_stopping_monitor = EarlyStopping(patience=5,restore_best_weights=True)\n",
    "    model.fit(x=X,y=y,epochs=nb_epoch,batch_size=batch_size_para,validation_data=(X_val,y_val),callbacks=[early_stopping_monitor,modelckpt_callback,history],verbose=verbose_para)\n",
    "    # save the trained_model\n",
    "    if save:\n",
    "        file_path = \"./saved_model\"\n",
    "        save_model(model,file_path)\n",
    "\n",
    "    return model,history\n",
    "\n",
    "# model = load_model(filepath, compile = True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-89-a761d4389948>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mtrained_model\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mhist\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbuild_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtraining\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtraining\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mvalidation\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mvalidation\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtemperature_norm\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtemperature_norm\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mlag_value\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m15\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mnb_epoch\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m150\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-88-329fa20fc248>\u001B[0m in \u001B[0;36mbuild_model\u001B[1;34m(training, validation, temperature_norm, lag_value, nb_epoch, regularization_parameter, batch_size_para, verbose_para, save)\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mbuild_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtraining\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSeries\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mvalidation\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSeries\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtemperature_norm\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSeries\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlag_value\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mnb_epoch\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mint\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mregularization_parameter\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mfloat\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0.01\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mbatch_size_para\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mint\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m32\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mverbose_para\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mint\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msave\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mbool\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m     \u001B[0mhistory\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mHistory\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m     \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minput_output_LSTM\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtraining\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtemperature_norm\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlag_value\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m     \u001B[0mX_val\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my_val\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minput_output_LSTM\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalidation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtemperature_norm\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlag_value\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m     \u001B[0mregularizers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0ml2\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ml\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mregularization_parameter\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-87-69d25e8a4af4>\u001B[0m in \u001B[0;36minput_output_LSTM\u001B[1;34m(training, temperature_norm, lag_value)\u001B[0m\n\u001B[0;32m     32\u001B[0m             \u001B[0mtime_stamp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mall_time_stamps\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mlag_value_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 34\u001B[1;33m             \u001B[0mtemperature_feed\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_av_temp\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtime_stamp\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtemperature_norm\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     35\u001B[0m             \u001B[0mX\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0msample_id\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mlag_value_index\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtemperature_feed\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-87-69d25e8a4af4>\u001B[0m in \u001B[0;36mget_av_temp\u001B[1;34m(time_stamp, temperature)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mget_av_temp\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtime_stamp\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTimestamp\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtemperature\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSeries\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m->\u001B[0m \u001B[0mfloat\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mtemperature\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtemperature\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdayofyear\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0mtime_stamp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdayofyear\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mget_weekday\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtime_stamp\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTimestamp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m->\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mtime_stamp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweekday\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\ProgrammaX100\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001B[0m in \u001B[0;36mnew_method\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m     63\u001B[0m         \u001B[0mother\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mitem_from_zerodim\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mother\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 65\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mother\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     66\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     67\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mnew_method\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\ProgrammaX100\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py\u001B[0m in \u001B[0;36m__eq__\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m     27\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0munpack_zerodim_and_defer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"__eq__\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     28\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__eq__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mother\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 29\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_cmp_method\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mother\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moperator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0meq\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     30\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     31\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0munpack_zerodim_and_defer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"__ne__\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\ProgrammaX100\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36m_cmp_method\u001B[1;34m(self, other, op)\u001B[0m\n\u001B[0;32m   5636\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5637\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0merrstate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"ignore\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 5638\u001B[1;33m                 \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcomparison_op\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mother\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mop\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   5639\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5640\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\ProgrammaX100\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001B[0m in \u001B[0;36mcomparison_op\u001B[1;34m(left, right, op)\u001B[0m\n\u001B[0;32m    248\u001B[0m             \u001B[0mwarnings\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msimplefilter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"ignore\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mDeprecationWarning\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    249\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0merrstate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"ignore\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 250\u001B[1;33m                 \u001B[0mres_values\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_na_arithmetic_op\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlvalues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrvalues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mop\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mis_cmp\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    251\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    252\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mres_values\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\ProgrammaX100\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\numpy\\core\\_ufunc_config.py\u001B[0m in \u001B[0;36m__exit__\u001B[1;34m(self, *exc_info)\u001B[0m\n\u001B[0;32m    436\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moldcall\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mseterrcall\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcall\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    437\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 438\u001B[1;33m     \u001B[1;32mdef\u001B[0m \u001B[0m__exit__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0mexc_info\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    439\u001B[0m         \u001B[0mseterr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moldstate\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    440\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcall\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0m_Unspecified\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "trained_model,hist = build_model(training=training,validation=validation,temperature_norm=temperature_norm,lag_value=15,nb_epoch=150)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# predictions\n",
    "# run the predictor ``warm'' on the trainingset --> before going to do predictions (remember matlab file)\n",
    "# History().history\n",
    "# loss = history.history[\"loss\"]\n",
    "# history.keys()\n",
    "\n",
    "# hist = trained_model[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def visualize_loss(history):\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(len(loss))\n",
    "    figure_layout(figsize=(10,8),titel=\"Training and Validation Loss\",xlabel=\"Epochs\",ylabel=\"MSE\",grid=False)\n",
    "    plt.plot(epochs, loss, \"b\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"r\", label=\"Validation loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "visualize_loss(hist)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# trained_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def daily_prediction(model: Sequential, TS_norm_full: pd.Series, temperature_norm: pd.Series, lag_value: int, daily_time_stamps: pd.DatetimeIndex):\n",
    "    if len(daily_time_stamps) != 48:\n",
    "            raise Exception(\"The test data doesn't equal 48 steps.\")\n",
    "    TS_copy = TS_norm_full.copy(deep= True)\n",
    "    history_predictions = pd.Series(index= daily_time_stamps)\n",
    "    history_reference = pd.Series(index= daily_time_stamps)\n",
    "    for i in np.arange(0,len(daily_time_stamps)):\n",
    "        time_stamp = daily_time_stamps[i]\n",
    "        index_time_stamp = TS_copy.index.get_loc(time_stamp) # want to predict the time_stamp\n",
    "        start = index_time_stamp - lag_value\n",
    "        end = index_time_stamp\n",
    "        history = TS_copy[start:end+1]\n",
    "        prediction_input, reference = input_output_LSTM(history, temperature_norm, lag_value)\n",
    "        y_hat = model.predict(prediction_input)\n",
    "        # integrate the prediction in the TS_copy to be used in the next iterate\n",
    "        TS_copy[time_stamp] = y_hat\n",
    "        history_predictions[i] = y_hat\n",
    "        history_reference[i] = reference\n",
    "\n",
    "    return history_predictions, history_reference\n",
    "\n",
    "# print(time_step_prediction(model = trained_model, TS = TS, temperature_norm= temperature_norm, lag_value= 3, daily_time_stamps= pd.date_range(start=pd.Time)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_all_days_of_year(serie: pd.Series)->set:\n",
    "    collection = set()\n",
    "    for date in serie.index:\n",
    "        collection.add(date.dayofyear)\n",
    "    return collection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test_set_prediction(model: Sequential, TS_norm_full: pd.Series, temperature_norm: pd.Series, lag_value: int, test_set:pd.Series, real_values: bool = True):\n",
    "    # assumption that the test set has no gaps in the dates is not valid\n",
    "    collection = list(get_all_days_of_year(test_set))\n",
    "    day_int = collection[0]\n",
    "    daily_time_stamps = test_set[test_set.index.dayofyear == day_int].index\n",
    "    (history_predictions, history_reference) = daily_prediction(model, TS_norm_full, temperature_norm, lag_value, daily_time_stamps)\n",
    "    all_predictions = history_predictions\n",
    "    all_references = history_reference\n",
    "\n",
    "    if len(collection) > 1:\n",
    "        for day_int in collection[1:]:\n",
    "            daily_time_stamps = test_set[test_set.index.dayofyear == day_int].index\n",
    "            (history_predictions, history_reference) = daily_prediction(model, TS_norm_full, temperature_norm, lag_value, daily_time_stamps)\n",
    "            all_predictions = all_predictions.append(history_predictions)\n",
    "            all_references = all_references.append(history_reference)\n",
    "\n",
    "    if real_values:\n",
    "        all_predictions = norm_inverse(all_predictions,scaler_history)\n",
    "        all_references = norm_inverse(all_references,scaler_history)\n",
    "\n",
    "    return all_predictions, all_references\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_predictions, all_references = test_set_prediction(trained_model, TS_norm_full, temperature_norm, 15, test, True)\n",
    "# print(\"all_predictions: %s \\n.\"%all_predictions)\n",
    "# print(\"all_references: %s \\n.\"%all_references)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def show_forecast(all_predictions, all_references):\n",
    "    axis = figure_layout(figsize=(10,8),titel=\"\",xlabel=\"date\",ylabel=\"kWh\")\n",
    "    labels = [\"True Future\", \"Model Prediction\"]\n",
    "\n",
    "    all_references.plot(ax=axis, lw= 3.0, grid= True)\n",
    "    all_predictions.plot(ax=axis, lw= 3.0, grid= True)\n",
    "    axis.legend(labels)\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "# show_forecast(all_predictions[0:48],all_references[0:48])\n",
    "\n",
    "def show_all_forecasts(all_predictions, all_references):\n",
    "    collection = get_all_days_of_year(all_predictions)\n",
    "    for day_int in collection:\n",
    "        predictions = all_predictions[all_predictions.index.dayofyear == day_int]\n",
    "        references = all_references[all_references.index.dayofyear == day_int]\n",
    "        show_forecast(predictions, references)\n",
    "    plt.show()\n",
    "\n",
    "show_all_forecasts(all_predictions,all_references)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}