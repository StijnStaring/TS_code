{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "\"\"\"\n",
    "This file is implementing the vanilla LSTM.\n",
    "The test set used are the 31 days of December of a single time-serie of the 261 time-series with measurements of the full year 2017.\n",
    "Missing days are estimated.\n",
    "Naive basemodels that are used are the mean forecast and the MAPE-minimization.\n",
    "Evaluation metrics used: MSE, RMSE, NRMSE, MAE\n",
    "####################################################\n",
    "\n",
    "calculate the MSE on the total test set and for each day of the week.\n",
    "Should normalize history and temperature with min max\n",
    "Rest: weekday, time, holiday use one hot encoder\n",
    "Stack different LSTM blocks --> hidden nodes serve as inputs for next LSTM's\n",
    "Use finally a fully connected layer to generate an output\n",
    "Use different learning rules: adam!!, stochastic gradient descent, Adagrad, Adadelta and RMSProp\n",
    "Adam has parameters: learning rate, momentum and decay\n",
    "play with mini batches\n",
    "\n",
    "Inputs:\n",
    "1. history ok\n",
    "2. temp ok\n",
    "3. day week ok\n",
    "4. time ok\n",
    "5. holiday\n",
    "6. (previous week future lag)\n",
    "7. previous week error history lag --> how good are you following previous week\n",
    "just the difference between the values\n",
    "8. previous weeks load at the same moment in time and the temperatures of these days\n",
    "\"\"\"\n"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\nThis file is implementing the vanilla LSTM.\\nThe test set used are the 31 days of December of a single time-serie of the 261 time-series with measurements of the full year 2017.\\nMissing days are estimated.\\nNaive basemodels that are used are the mean forecast and the MAPE-minimization.\\nEvaluation metrics used: MSE, RMSE, NRMSE, MAE\\n####################################################\\n\\ncalculate the MSE on the total test set and for each day of the week.\\nShould normalize history and temperature with min max\\nRest: weekday, time, holiday use one hot encoder\\nStack different LSTM blocks --> hidden nodes serve as inputs for next LSTM's\\nUse finally a fully connected layer to generate an output\\nUse different learning rules: adam!!, stochastic gradient descent, Adagrad, Adadelta and RMSProp\\nAdam has parameters: learning rate, momentum and decay\\nplay with mini batches\\n\\nInputs:\\n1. history ok\\n2. temp ok\\n3. day week ok\\n4. time ok\\n5. holiday\\n6. (previous week future lag)\\n7. previous week error history lag --> how good are you following previous week\\njust the difference between the values\\n8. previous weeks load at the same moment in time and the temperatures of these days\\n\""
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from forecasting_functions import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# importing the data\n",
    "Stijn = True\n",
    "fullYearpath = None\n",
    "av_temperaturepath = None\n",
    "if Stijn:\n",
    "    fullYearpath = \"D:\\Onedrive\\Leuven\\Final project\\data\\Forecasting_writtendata\\FullYear.csv\"\n",
    "    av_temperaturepath = \"D:\\Onedrive\\Leuven\\Final project\\data\\weather-avg.csv\"\n",
    "else:\n",
    "    raise Exception(\"Put some paths here.\")\n",
    "fullYeardata = pd.read_csv(fullYearpath,index_col= \"date\",parse_dates= True)\n",
    "av_temperature = pd.read_csv(av_temperaturepath,index_col='meter_id')\n",
    "av_temperature = av_temperature.transpose()\n",
    "av_temperature.index = pd.to_datetime(av_temperature.index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of missing values: 0. \n",
      "\n",
      "amount of missing values: 0. \n",
      "\n",
      "amount of missing values: 0. \n",
      "\n",
      "amount of missing values: 0. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_serie1 = time_serie(fullYeardata[fullYeardata.columns[0]], av_temperature)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "(381, 3, 59)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y = input_output_LSTM(training, temperature_norm, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_model_stateless2(training: pd.Series,validation: pd.Series, temperature_norm: pd.Series, lag_value: int,nb_epoch: int = 1, regularization_parameter: float = 0.01,batch_size_para: int = 32,verbose_para: int = 1, save: bool = False):\n",
    "    history = History()\n",
    "    X,y = input_output_LSTM(training, temperature_norm, lag_value)\n",
    "    X_val,y_val = input_output_LSTM(validation, temperature_norm, lag_value)\n",
    "    regularizers.l2(l=regularization_parameter)\n",
    "    model = Sequential()\n",
    "    # no initial state is given --> hidden state are tensors filled with zeros\n",
    "    # dropout=None,recurrent_dropout=None\n",
    "    model.add(LSTM(units=20,activation='tanh',stateful= False, batch_input_shape=(batch_size_para,X.shape[1],X.shape[2])))\n",
    "    model.add(Dense(units=20,activation='relu',kernel_regularizer='l2'))\n",
    "    # model.add(Dropout(0.10))\n",
    "    model.add(Dense(units=y.shape[1],activation='relu',kernel_regularizer='l2'))\n",
    "    model.compile(optimizer='adam',loss='mse')\n",
    "    early_stopping_monitor = EarlyStopping(patience=5,restore_best_weights=True)\n",
    "    # shuffle false --> not shuffle the training data\n",
    "    model.fit(x=X,y=y,epochs=nb_epoch,shuffle= False, batch_size=batch_size_para,validation_data=(X_val,y_val),callbacks=[early_stopping_monitor,history],verbose=verbose_para)\n",
    "    # save the trained_model\n",
    "    if save:\n",
    "        file_path = \"model.h5\"\n",
    "        save_model(model,file_path)\n",
    "\n",
    "    return model,history\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 381.\n",
      "(320, 3, 59)\n",
      "(32, 3, 59)\n"
     ]
    }
   ],
   "source": [
    "print(\"length: %s.\"%len(X))\n",
    "training, validation = generate_training_validation_division(X,32,0.901316)\n",
    "print(training.shape)\n",
    "print(validation.shape)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# def def build_model_stateless1(training: pd.Series,validation: pd.Series, temperature_norm: pd.Series, lag_value: int,nb_epoch: int = 1, regularization_parameter: float = 0.01,batch_size_para: int = 32,verbose_para: int = 1, save: bool = False):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "trained_model,hist = build_model_stateless1(training=training,validation=validation,temperature_norm=temperature_norm,lag_value=3,nb_epoch=150, verbose_para= 0)\n",
    "# trained_model.save('model.h5')\n",
    "# model = load_model(\"D:\\AI_time_series_repos\\TS_code\\Forecasting\\LSTM\\model.h5\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_model_stateless1(training: pd.Series,validation: pd.Series, temperature_norm: pd.Series, lag_value: int,nb_epoch: int = 1, regularization_parameter: float = 0.01,batch_size_para: int = 32,verbose_para: int = 1, save: bool = False):\n",
    "    history = History()\n",
    "    X,y = input_output_LSTM(training, temperature_norm, lag_value)\n",
    "    X_val,y_val = input_output_LSTM(validation, temperature_norm, lag_value)\n",
    "    regularizers.l2(l=regularization_parameter)\n",
    "    model = Sequential()\n",
    "    # no initial state is given --> hidden state are tensors filled with zeros\n",
    "    # dropout=None,recurrent_dropout=None\n",
    "    model.add(LSTM(units=20,activation='tanh',input_shape=(X.shape[1],X.shape[2])))\n",
    "    model.add(Dense(units=20,activation='relu',kernel_regularizer='l2'))\n",
    "    # model.add(Dropout(0.10))\n",
    "    model.add(Dense(units=y.shape[1],activation='relu',kernel_regularizer='l2'))\n",
    "    model.compile(optimizer='adam',loss='mse')\n",
    "    early_stopping_monitor = EarlyStopping(patience=5,restore_best_weights=True)\n",
    "    # shuffle false --> not shuffle the training data\n",
    "    model.fit(x=X,y=y,epochs=nb_epoch,shuffle= False, batch_size=batch_size_para,validation_data=(X_val,y_val),callbacks=[early_stopping_monitor,history],verbose=verbose_para)\n",
    "    # save the trained_model\n",
    "    if save:\n",
    "        file_path = \"model.h5\"\n",
    "        save_model(model,file_path)\n",
    "\n",
    "    return model,history\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def daily_prediction_stateless1(model: Sequential, TS_norm_full: pd.Series, temperature_norm: pd.Series, lag_value: int, daily_time_stamps: pd.DatetimeIndex):\n",
    "    if len(daily_time_stamps) != 48:\n",
    "            raise Exception(\"The test data doesn't equal 48 steps.\")\n",
    "    TS_copy = TS_norm_full.copy(deep= True)\n",
    "    history_predictions = pd.Series(index= daily_time_stamps)\n",
    "    history_reference = pd.Series(index= daily_time_stamps)\n",
    "    for i in np.arange(0,len(daily_time_stamps)):\n",
    "        time_stamp = daily_time_stamps[i]\n",
    "        index_time_stamp = TS_copy.index.get_loc(time_stamp) # want to predict the time_stamp\n",
    "        start = index_time_stamp - lag_value\n",
    "        end = index_time_stamp\n",
    "        history = TS_copy[start:end+1]\n",
    "        prediction_input, reference = input_output_LSTM(history, temperature_norm, lag_value) # also the value to predict should be given\n",
    "        y_hat = model.predict(prediction_input)\n",
    "        # integrate the prediction in the TS_copy to be used in the next iterate\n",
    "        TS_copy[time_stamp] = y_hat\n",
    "        history_predictions[time_stamp] = y_hat\n",
    "        history_reference[time_stamp] = reference\n",
    "\n",
    "    return history_predictions, history_reference\n",
    "\n",
    "# print(time_step_prediction(model = trained_model, TS = TS, temperature_norm= temperature_norm, lag_value= 3, daily_time_stamps= pd.date_range(start=pd.Time)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def get_all_days_of_year(serie: pd.Series)->set:\n",
    "    collection = set()\n",
    "    for date in serie.index:\n",
    "        collection.add(date.dayofyear)\n",
    "    return collection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def test_set_prediction(model: Sequential, TS_norm_full: pd.Series, temperature_norm: pd.Series, lag_value: int, test_set:pd.Series, real_values: bool = True):\n",
    "    # assumption that the test set has no gaps in the dates is not valid\n",
    "    collection = list(get_all_days_of_year(test_set))\n",
    "    day_int = collection[0]\n",
    "    daily_time_stamps = test_set[test_set.index.dayofyear == day_int].index\n",
    "    (history_predictions, history_reference) = daily_prediction_stateless1(model, TS_norm_full, temperature_norm, lag_value, daily_time_stamps)\n",
    "    all_predictions = history_predictions\n",
    "    all_references = history_reference\n",
    "\n",
    "    if len(collection) > 1:\n",
    "        for day_int in collection[1:]:\n",
    "            daily_time_stamps = test_set[test_set.index.dayofyear == day_int].index\n",
    "            (history_predictions, history_reference) = daily_prediction_stateless1(model, TS_norm_full, temperature_norm, lag_value, daily_time_stamps)\n",
    "            all_predictions = all_predictions.append(history_predictions)\n",
    "            all_references = all_references.append(history_reference)\n",
    "\n",
    "    if real_values:\n",
    "        all_predictions = norm_inverse(all_predictions,scaler_history)\n",
    "        all_references = norm_inverse(all_references,scaler_history)\n",
    "\n",
    "    return all_predictions, all_references\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from Test_basemodel_functions import Switcher\n",
    "\n",
    "def get_performance(all_predictions: pd.Series, all_references: pd.Series, metric: str = 'NRMSE'):\n",
    "    return Switcher(metric, all_predictions, all_references)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "all_predictions, all_references = test_set_prediction(trained_model, TS_norm_full, temperature_norm, 3, test, True)\n",
    "# print(\"all_predictions: %s \\n.\"%all_predictions)\n",
    "# print(\"all_references: %s \\n.\"%all_references)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def show_forecast(all_predictions, all_references, ID: str, day_int: str, save: bool):\n",
    "    axis = figure_layout(figsize=(10,8),titel=\"\",xlabel=\"date\",ylabel=\"kWh\", dpi= 300)\n",
    "    labels = [\"True Future\", \"Model Prediction\"]\n",
    "\n",
    "    all_references.plot(ax=axis, lw= 3.0, grid= True)\n",
    "    all_predictions.plot(ax=axis, lw= 3.0, grid= True)\n",
    "    axis.legend(labels)\n",
    "\n",
    "    if save:\n",
    "        path = \"Vanilla_LSTM_figures/\"\n",
    "        fname = path + \"ID\" + ID + \"_Day\" + day_int + \".png\"\n",
    "        plt.savefig(fname, dpi=None, facecolor='w', edgecolor='w', orientation='portrait', format=None,\n",
    "                    transparent=False, bbox_inches='tight', pad_inches=0.1, metadata=None)\n",
    "\n",
    "# show_forecast(all_predictions[0:48],all_references[0:48])\n",
    "\n",
    "def show_all_forecasts(all_predictions, all_references,ID: str, save: bool = True):\n",
    "    collection = get_all_days_of_year(all_predictions)\n",
    "    for day_int in collection:\n",
    "        predictions = all_predictions[all_predictions.index.dayofyear == day_int]\n",
    "        references = all_references[all_references.index.dayofyear == day_int]\n",
    "        show_forecast(predictions, references, ID, str(day_int), save)\n",
    "    plt.show()\n",
    "\n",
    "show_all_forecasts(all_predictions,all_references, name, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def repeated_performance(TS_norm_full: pd.Series, training: pd.Series, validation: pd.Series, test: pd.Series, temperature_norm: pd.Series, lag_value = 3, nb_epoch = 150, vb = 0, repeat = 2):\n",
    "    collection = []\n",
    "    for i in range(repeat):\n",
    "        trained_model,hist = build_model_stateless1(training=training,validation=validation,temperature_norm=temperature_norm,lag_value=lag_value,nb_epoch=nb_epoch, verbose_para= vb)\n",
    "        all_predictions, all_references = test_set_prediction(trained_model, TS_norm_full, temperature_norm, lag_value, test, True)\n",
    "        p = get_performance(all_predictions, all_references)\n",
    "        collection.append(p)\n",
    "    return np.array(collection)\n",
    "df = pd.DataFrame()\n",
    "df[TS.name] = repeated_performance(TS_norm_full, training, validation, test, temperature_norm, lag_value = 3, nb_epoch = 150, vb = 0, repeat = 2)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time as t\n",
    "results_file_name = str(t.time()) + \".txt\"\n",
    "results_file = open(results_file_name, \"w\")\n",
    "results_file.write(\"This file displays the results of the hyperparameter search.\")\n",
    "results_file.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data= np.arange(0,25,2))\n",
    "df[\"1\"] = np.zeros(13)\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}