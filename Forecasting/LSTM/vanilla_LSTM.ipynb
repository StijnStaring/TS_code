{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "\"\"\"\n",
    "This file is implementing the vanilla LSTM.\n",
    "The test set used are the 31 days of December of a single time-serie of the 261 time-series with measurements of the full year 2017.\n",
    "Missing days are estimated.\n",
    "Naive basemodels that are used are the mean forecast and the MAPE-minimization.\n",
    "Evaluation metrics used: MSE, RMSE, NRMSE, MAE\n",
    "####################################################\n",
    "\n",
    "calculate the MSE on the total test set and for each day of the week.\n",
    "Should normalize history and temperature with min max\n",
    "Rest: weekday, time, holiday use one hot encoder\n",
    "Stack different LSTM blocks --> hidden nodes serve as inputs for next LSTM's\n",
    "Use finally a fully connected layer to generate an output\n",
    "Use different learning rules: adam!!, stochastic gradient descent, Adagrad, Adadelta and RMSProp\n",
    "Adam has parameters: learning rate, momentum and decay\n",
    "play with mini batches\n",
    "\n",
    "Inputs:\n",
    "1. history ok\n",
    "2. temp ok\n",
    "3. day week ok\n",
    "4. time ok\n",
    "5. holiday\n",
    "6. (previous week future lag)\n",
    "7. previous week error history lag --> how good are you following previous week\n",
    "just the difference between the values\n",
    "8. previous weeks load at the same moment in time and the temperatures of these days\n",
    "\"\"\"\n"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\nThis file is implementing the vanilla LSTM.\\nThe test set used are the 31 days of December of a single time-serie of the 261 time-series with measurements of the full year 2017.\\nMissing days are estimated.\\nNaive basemodels that are used are the mean forecast and the MAPE-minimization.\\nEvaluation metrics used: MSE, RMSE, NRMSE, MAE\\n####################################################\\n\\ncalculate the MSE on the total test set and for each day of the week.\\nShould normalize history and temperature with min max\\nRest: weekday, time, holiday use one hot encoder\\nStack different LSTM blocks --> hidden nodes serve as inputs for next LSTM's\\nUse finally a fully connected layer to generate an output\\nUse different learning rules: adam!!, stochastic gradient descent, Adagrad, Adadelta and RMSProp\\nAdam has parameters: learning rate, momentum and decay\\nplay with mini batches\\n\\nInputs:\\n1. history ok\\n2. temp ok\\n3. day week ok\\n4. time ok\\n5. holiday\\n6. (previous week future lag)\\n7. previous week error history lag --> how good are you following previous week\\njust the difference between the values\\n8. previous weeks load at the same moment in time and the temperatures of these days\\n\""
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd # pandas\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import casadi as ca\n",
    "from Test_basemodel_functions import *\n",
    "\n",
    "plt.rc('axes', linewidth=2)\n",
    "plt.rc('axes', labelsize= 16)\n",
    "plt.rc('axes',titlesize = 18)\n",
    "plt.rc('legend',fontsize=14)\n",
    "plt.rc('xtick', labelsize=16)\n",
    "plt.rc('ytick', labelsize=16)\n",
    "plt.rc('figure',figsize=(10,8))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# importing the data\n",
    "fullYeardata = pd.read_csv(\"D:\\Onedrive\\Leuven\\Final project\\data\\Forecasting_writtendata\\FullYear.csv\",index_col= \"date\",parse_dates= True)\n",
    "av_temperature = pd.read_csv(\"D:\\Onedrive\\Leuven\\Final project\\data\\weather-avg.csv\",index_col='meter_id')\n",
    "av_temperature = av_temperature.transpose()\n",
    "av_temperature.index = pd.to_datetime(av_temperature.index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "name = fullYeardata.columns[0]\n",
    "TS = fullYeardata[name]\n",
    "temperature = av_temperature[name]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# subsitute the missing values by prev week < prev day < mean of all the values at that time of the day (rarely used)\n",
    "def substitute_missing_values(TS: pd.Series):\n",
    "    for date in TS.index:\n",
    "        if np.isnan(TS[date]):\n",
    "            prev_week =  date + dt.timedelta(days=-7)\n",
    "            prev_day = date + dt.timedelta(days=-1)\n",
    "            if not np.isnan(TS[prev_week]):\n",
    "                TS[date] = TS[prev_week]\n",
    "\n",
    "            elif not np.isnan(TS[prev_day]):\n",
    "                TS[date] = TS[prev_day]\n",
    "\n",
    "            else:\n",
    "                temp = TS[TS.index.hour == date.hour]\n",
    "                data = temp[temp.index.minute == date.minute]\n",
    "                TS[date] = data.mean()\n",
    "    print(\"amount of missing values: %s. \\n\"%TS.isnull().sum())\n",
    "    return TS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of missing values: 0. \n",
      "\n",
      "amount of missing values: 0. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# all the training dates are present, dates from the test set can be missing.\n",
    "\n",
    "# normalize the data --> min/max method (when using a single time serie)\n",
    "temperature_norm = norm(temperature)\n",
    "TS_norm = norm(TS)\n",
    "# temp = TS_norm[TS_norm.index.month != 12]\n",
    "# training = temp[temp != 11]\n",
    "# validation = TS_norm[TS_norm.index.month == 11]\n",
    "# test = TS_norm[TS_norm.index.month == 12]\n",
    "# remove from the test set all the days that contain nan values -> only estimate real days\n",
    "training = TS_norm[0:336]\n",
    "validation = TS_norm[336:384]\n",
    "test = TS_norm[384:528]\n",
    "test.dropna(inplace=True)\n",
    "# substitute the missing values\n",
    "training = substitute_missing_values(training)\n",
    "TS_norm_full = substitute_missing_values(TS_norm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def get_av_temp(time_stamp: pd.Timestamp,temperature: pd.Series)-> float:\n",
    "    return temperature[temperature.index.dayofyear == time_stamp.dayofyear]\n",
    "\n",
    "def get_weekday(time_stamp: pd.Timestamp)-> int:\n",
    "    return time_stamp.weekday()\n",
    "\n",
    "def get_daytime(time_stamp: pd.Timestamp):\n",
    "    value = time_stamp.hour*2\n",
    "    if time_stamp.minute == 30:\n",
    "        value = value + 1\n",
    "    return value\n",
    "\n",
    "def is_holiday(time_stamp: pd.Timestamp, holidays: pd.DatetimeIndex)->bool:\n",
    "    return any(time_stamp.dayofyear == holidays.dayofyear)\n",
    "\n",
    "\n",
    "# forecast one time stamp at the time --> for loop to forecast the 48 time stamps\n",
    "def input_output_LSTM(training, temperature_norm, lag_value: int):\n",
    "    holidays = EnglandAndWalesHolidayCalendar().holidays(start=pd.Timestamp('2017-01-01'),end=pd.Timestamp('2017-12-31'))\n",
    "    amount_forecasts = len(training) - lag_value\n",
    "    amount_features = 1+1+7+48+2\n",
    "    X = np.zeros((amount_forecasts,lag_value,amount_features))\n",
    "    y = np.zeros((amount_forecasts,1))\n",
    "\n",
    "    for sample_id in np.arange(0,amount_forecasts):\n",
    "\n",
    "        history = training.values[sample_id:lag_value + sample_id]\n",
    "        y[sample_id] = training.values[lag_value + sample_id]\n",
    "        X[sample_id,:,0] = history\n",
    "        all_time_stamps = training.index[sample_id:lag_value + sample_id]\n",
    "        for lag_value_index in np.arange(0,lag_value): # goes from old to new\n",
    "            time_stamp = all_time_stamps[lag_value_index]\n",
    "\n",
    "            temperature_feed = get_av_temp(time_stamp,temperature_norm)\n",
    "            X[sample_id,lag_value_index,1] = temperature_feed\n",
    "\n",
    "            weekday = np.zeros(7)\n",
    "            day = get_weekday(time_stamp) # 0 - 6\n",
    "            weekday[day] = 1\n",
    "            X[sample_id,lag_value_index,2:9] = weekday\n",
    "\n",
    "            time = np.zeros(48)\n",
    "            time_of_day = get_daytime(time_stamp) # 0 - 47\n",
    "            time[time_of_day] = 1\n",
    "            X[sample_id,lag_value_index,9:57] = time\n",
    "\n",
    "            holiday = np.zeros(2)\n",
    "            hol = is_holiday(time_stamp,holidays) # [no, yes]\n",
    "            if hol:\n",
    "                holiday[1] = 1\n",
    "            else:\n",
    "                holiday[0] = 1\n",
    "            X[sample_id,lag_value_index,57:59] = holiday\n",
    "\n",
    "\n",
    "    return X,y\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\ProgrammaX100\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\ProgrammaX100\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\ProgrammaX100\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\ProgrammaX100\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\ProgrammaX100\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\ProgrammaX100\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\ProgrammaX100\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\ProgrammaX100\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\ProgrammaX100\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\ProgrammaX100\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\ProgrammaX100\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\ProgrammaX100\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense,  LSTM,Embedding\n",
    "from keras.models import Sequential, save_model, load_model\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint, History\n",
    "\n",
    "path_checkpoint = \"model_checkpoint.h5\"\n",
    "modelckpt_callback = ModelCheckpoint(monitor=\"val_loss\",filepath=path_checkpoint,verbose=1,save_weights_only=True,save_best_only=True)\n",
    "def build_model(training: pd.Series,validation: pd.Series, temperature_norm: pd.Series, lag_value: int,nb_epoch: int = 1, regularization_parameter: float = 0.01,batch_size_para: int = 32,verbose_para: int = 1, save: bool = False):\n",
    "    history = History()\n",
    "    X,y = input_output_LSTM(training, temperature_norm, lag_value)\n",
    "    X_val,y_val = input_output_LSTM(validation, temperature_norm, lag_value)\n",
    "    regularizers.l2(l=regularization_parameter)\n",
    "    model = Sequential()\n",
    "    # no initial state is given --> hidden state are tensors filled with zeros\n",
    "    # dropout=None,recurrent_dropout=None\n",
    "    model.add(LSTM(units=20,activation='tanh',input_shape=(X.shape[1],X.shape[2])))\n",
    "    model.add(Dense(units=20,activation='relu',kernel_regularizer='l2'))\n",
    "    # model.add(Dropout(0.10))\n",
    "    model.add(Dense(units=y.shape[1],activation='relu',kernel_regularizer='l2'))\n",
    "    model.compile(optimizer='adam',loss='mse')\n",
    "    early_stopping_monitor = EarlyStopping(patience=2,restore_best_weights=True)\n",
    "    model.fit(x=X,y=y,epochs=nb_epoch,batch_size=batch_size_para,validation_data=(X_val,y_val),callbacks=[early_stopping_monitor,modelckpt_callback,history],verbose=verbose_para)\n",
    "    # save the trained_model\n",
    "    if save:\n",
    "        file_path = \"./saved_model\"\n",
    "        save_model(model,file_path)\n",
    "\n",
    "    return model,history\n",
    "\n",
    "# model = load_model(filepath, compile = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ProgrammaX100\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 333 samples, validate on 45 samples\n",
      "Epoch 1/150\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.2246 - val_loss: 0.2107\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.21070, saving model to model_checkpoint.h5\n",
      "Epoch 2/150\n",
      "333/333 [==============================] - 0s 99us/step - loss: 0.2063 - val_loss: 0.1944\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.21070 to 0.19445, saving model to model_checkpoint.h5\n",
      "Epoch 3/150\n",
      "333/333 [==============================] - 0s 141us/step - loss: 0.1898 - val_loss: 0.1793\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.19445 to 0.17927, saving model to model_checkpoint.h5\n",
      "Epoch 4/150\n",
      "333/333 [==============================] - 0s 141us/step - loss: 0.1747 - val_loss: 0.1655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.17927 to 0.16550, saving model to model_checkpoint.h5\n",
      "Epoch 5/150\n",
      "333/333 [==============================] - 0s 240us/step - loss: 0.1608 - val_loss: 0.1525\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.16550 to 0.15250, saving model to model_checkpoint.h5\n",
      "Epoch 6/150\n",
      "333/333 [==============================] - 0s 174us/step - loss: 0.1481 - val_loss: 0.1406\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.15250 to 0.14062, saving model to model_checkpoint.h5\n",
      "Epoch 7/150\n",
      "333/333 [==============================] - 0s 141us/step - loss: 0.1363 - val_loss: 0.1293\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.14062 to 0.12934, saving model to model_checkpoint.h5\n",
      "Epoch 8/150\n",
      "333/333 [==============================] - 0s 145us/step - loss: 0.1254 - val_loss: 0.1193\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.12934 to 0.11935, saving model to model_checkpoint.h5\n",
      "Epoch 9/150\n",
      "333/333 [==============================] - 0s 94us/step - loss: 0.1154 - val_loss: 0.1098\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.11935 to 0.10982, saving model to model_checkpoint.h5\n",
      "Epoch 10/150\n",
      "333/333 [==============================] - 0s 94us/step - loss: 0.1062 - val_loss: 0.1011\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.10982 to 0.10114, saving model to model_checkpoint.h5\n",
      "Epoch 11/150\n",
      "333/333 [==============================] - 0s 94us/step - loss: 0.0978 - val_loss: 0.0931\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.10114 to 0.09313, saving model to model_checkpoint.h5\n",
      "Epoch 12/150\n",
      "333/333 [==============================] - 0s 159us/step - loss: 0.0900 - val_loss: 0.0856\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.09313 to 0.08561, saving model to model_checkpoint.h5\n",
      "Epoch 13/150\n",
      "333/333 [==============================] - 0s 94us/step - loss: 0.0828 - val_loss: 0.0787\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.08561 to 0.07873, saving model to model_checkpoint.h5\n",
      "Epoch 14/150\n",
      "333/333 [==============================] - 0s 94us/step - loss: 0.0762 - val_loss: 0.0728\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.07873 to 0.07282, saving model to model_checkpoint.h5\n",
      "Epoch 15/150\n",
      "333/333 [==============================] - 0s 141us/step - loss: 0.0702 - val_loss: 0.0670\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.07282 to 0.06696, saving model to model_checkpoint.h5\n",
      "Epoch 16/150\n",
      "333/333 [==============================] - 0s 138us/step - loss: 0.0646 - val_loss: 0.0616\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.06696 to 0.06162, saving model to model_checkpoint.h5\n",
      "Epoch 17/150\n",
      "333/333 [==============================] - 0s 141us/step - loss: 0.0595 - val_loss: 0.0567\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.06162 to 0.05670, saving model to model_checkpoint.h5\n",
      "Epoch 18/150\n",
      "333/333 [==============================] - 0s 94us/step - loss: 0.0549 - val_loss: 0.0522\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.05670 to 0.05217, saving model to model_checkpoint.h5\n",
      "Epoch 19/150\n",
      "333/333 [==============================] - 0s 136us/step - loss: 0.0506 - val_loss: 0.0479\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.05217 to 0.04795, saving model to model_checkpoint.h5\n",
      "Epoch 20/150\n",
      "333/333 [==============================] - 0s 97us/step - loss: 0.0467 - val_loss: 0.0443\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.04795 to 0.04427, saving model to model_checkpoint.h5\n",
      "Epoch 21/150\n",
      "333/333 [==============================] - 0s 141us/step - loss: 0.0431 - val_loss: 0.0408\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.04427 to 0.04082, saving model to model_checkpoint.h5\n",
      "Epoch 22/150\n",
      "333/333 [==============================] - 0s 94us/step - loss: 0.0398 - val_loss: 0.0378\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.04082 to 0.03776, saving model to model_checkpoint.h5\n",
      "Epoch 23/150\n",
      "333/333 [==============================] - 0s 145us/step - loss: 0.0368 - val_loss: 0.0349\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.03776 to 0.03492, saving model to model_checkpoint.h5\n",
      "Epoch 24/150\n",
      "333/333 [==============================] - 0s 109us/step - loss: 0.0341 - val_loss: 0.0323\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.03492 to 0.03229, saving model to model_checkpoint.h5\n",
      "Epoch 25/150\n",
      "333/333 [==============================] - 0s 141us/step - loss: 0.0316 - val_loss: 0.0299\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.03229 to 0.02995, saving model to model_checkpoint.h5\n",
      "Epoch 26/150\n",
      "333/333 [==============================] - 0s 94us/step - loss: 0.0293 - val_loss: 0.0277\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.02995 to 0.02770, saving model to model_checkpoint.h5\n",
      "Epoch 27/150\n",
      "333/333 [==============================] - 0s 156us/step - loss: 0.0273 - val_loss: 0.0257\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.02770 to 0.02566, saving model to model_checkpoint.h5\n",
      "Epoch 28/150\n",
      "333/333 [==============================] - 0s 103us/step - loss: 0.0254 - val_loss: 0.0240\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.02566 to 0.02396, saving model to model_checkpoint.h5\n",
      "Epoch 29/150\n",
      "333/333 [==============================] - 0s 94us/step - loss: 0.0237 - val_loss: 0.0223\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.02396 to 0.02227, saving model to model_checkpoint.h5\n",
      "Epoch 30/150\n",
      "333/333 [==============================] - 0s 165us/step - loss: 0.0221 - val_loss: 0.0208\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.02227 to 0.02081, saving model to model_checkpoint.h5\n",
      "Epoch 31/150\n",
      "333/333 [==============================] - 0s 92us/step - loss: 0.0207 - val_loss: 0.0195\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.02081 to 0.01954, saving model to model_checkpoint.h5\n",
      "Epoch 32/150\n",
      "333/333 [==============================] - 0s 141us/step - loss: 0.0194 - val_loss: 0.0183\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.01954 to 0.01827, saving model to model_checkpoint.h5\n",
      "Epoch 33/150\n",
      "333/333 [==============================] - 0s 94us/step - loss: 0.0183 - val_loss: 0.0171\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.01827 to 0.01709, saving model to model_checkpoint.h5\n",
      "Epoch 34/150\n",
      "333/333 [==============================] - 0s 123us/step - loss: 0.0172 - val_loss: 0.0161\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.01709 to 0.01612, saving model to model_checkpoint.h5\n",
      "Epoch 35/150\n",
      "333/333 [==============================] - 0s 97us/step - loss: 0.0163 - val_loss: 0.0153\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.01612 to 0.01531, saving model to model_checkpoint.h5\n",
      "Epoch 36/150\n",
      "333/333 [==============================] - 0s 94us/step - loss: 0.0154 - val_loss: 0.0145\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.01531 to 0.01445, saving model to model_checkpoint.h5\n",
      "Epoch 37/150\n",
      "333/333 [==============================] - 0s 158us/step - loss: 0.0147 - val_loss: 0.0137\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.01445 to 0.01368, saving model to model_checkpoint.h5\n",
      "Epoch 38/150\n",
      "333/333 [==============================] - 0s 78us/step - loss: 0.0140 - val_loss: 0.0132\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.01368 to 0.01318, saving model to model_checkpoint.h5\n",
      "Epoch 39/150\n",
      "333/333 [==============================] - 0s 94us/step - loss: 0.0133 - val_loss: 0.0125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.01318 to 0.01250, saving model to model_checkpoint.h5\n",
      "Epoch 40/150\n",
      "333/333 [==============================] - 0s 141us/step - loss: 0.0127 - val_loss: 0.0122\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.01250 to 0.01221, saving model to model_checkpoint.h5\n",
      "Epoch 41/150\n",
      "333/333 [==============================] - 0s 120us/step - loss: 0.0122 - val_loss: 0.0118\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.01221 to 0.01184, saving model to model_checkpoint.h5\n",
      "Epoch 42/150\n",
      "333/333 [==============================] - 0s 94us/step - loss: 0.0117 - val_loss: 0.0113\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.01184 to 0.01132, saving model to model_checkpoint.h5\n",
      "Epoch 43/150\n",
      "333/333 [==============================] - 0s 141us/step - loss: 0.0113 - val_loss: 0.0110\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.01132 to 0.01100, saving model to model_checkpoint.h5\n",
      "Epoch 44/150\n",
      "333/333 [==============================] - 0s 185us/step - loss: 0.0109 - val_loss: 0.0106\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.01100 to 0.01065, saving model to model_checkpoint.h5\n",
      "Epoch 45/150\n",
      "333/333 [==============================] - 0s 62us/step - loss: 0.0106 - val_loss: 0.0104\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.01065 to 0.01040, saving model to model_checkpoint.h5\n",
      "Epoch 46/150\n",
      "333/333 [==============================] - 0s 188us/step - loss: 0.0103 - val_loss: 0.0100\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.01040 to 0.01001, saving model to model_checkpoint.h5\n",
      "Epoch 47/150\n",
      "333/333 [==============================] - 0s 182us/step - loss: 0.0100 - val_loss: 0.0101\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.01001\n",
      "Epoch 48/150\n",
      "333/333 [==============================] - 0s 137us/step - loss: 0.0097 - val_loss: 0.0099\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.01001 to 0.00991, saving model to model_checkpoint.h5\n",
      "Epoch 49/150\n",
      "333/333 [==============================] - 0s 94us/step - loss: 0.0095 - val_loss: 0.0095\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00991 to 0.00954, saving model to model_checkpoint.h5\n",
      "Epoch 50/150\n",
      "333/333 [==============================] - 0s 245us/step - loss: 0.0093 - val_loss: 0.0093\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00954 to 0.00931, saving model to model_checkpoint.h5\n",
      "Epoch 51/150\n",
      "333/333 [==============================] - 0s 78us/step - loss: 0.0091 - val_loss: 0.0094\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00931\n",
      "Epoch 52/150\n",
      "333/333 [==============================] - 0s 94us/step - loss: 0.0089 - val_loss: 0.0093\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00931 to 0.00930, saving model to model_checkpoint.h5\n",
      "Epoch 53/150\n",
      "333/333 [==============================] - 0s 94us/step - loss: 0.0088 - val_loss: 0.0091\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00930 to 0.00914, saving model to model_checkpoint.h5\n",
      "Epoch 54/150\n",
      "333/333 [==============================] - 0s 134us/step - loss: 0.0086 - val_loss: 0.0089\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00914 to 0.00887, saving model to model_checkpoint.h5\n",
      "Epoch 55/150\n",
      "333/333 [==============================] - 0s 111us/step - loss: 0.0085 - val_loss: 0.0089\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00887 to 0.00887, saving model to model_checkpoint.h5\n",
      "Epoch 56/150\n",
      "333/333 [==============================] - 0s 94us/step - loss: 0.0084 - val_loss: 0.0088\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00887 to 0.00882, saving model to model_checkpoint.h5\n",
      "Epoch 57/150\n",
      "333/333 [==============================] - 0s 141us/step - loss: 0.0083 - val_loss: 0.0087\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00882 to 0.00873, saving model to model_checkpoint.h5\n",
      "Epoch 58/150\n",
      "333/333 [==============================] - 0s 123us/step - loss: 0.0082 - val_loss: 0.0088\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00873\n",
      "Epoch 59/150\n",
      "333/333 [==============================] - 0s 120us/step - loss: 0.0081 - val_loss: 0.0087\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00873\n"
     ]
    }
   ],
   "source": [
    "trained_model,hist = build_model(training=training,validation=validation,temperature_norm=temperature_norm,lag_value=3,nb_epoch=150)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# predictions\n",
    "# run the predictor ``warm'' on the trainingset --> before going to do predictions (remember matlab file)\n",
    "# History().history\n",
    "# loss = history.history[\"loss\"]\n",
    "# history.keys()\n",
    "\n",
    "# hist = trained_model[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_loss(history):\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(len(loss))\n",
    "    figure_layout(figsize=(10,8),titel=\"Training and Validation Loss\",xlabel=\"Epochs\",ylabel=\"MSE\",grid=False)\n",
    "    plt.plot(epochs, loss, \"b\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"r\", label=\"Validation loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "visualize_loss(hist)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# trained_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "def daily_prediction(model: Sequential, TS_norm_full: pd.Series, temperature_norm: pd.Series, lag_value: int, daily_time_stamps: pd.DatetimeIndex):\n",
    "    if len(daily_time_stamps) != 48:\n",
    "            raise Exception(\"The test data doesn't equal 48 steps.\")\n",
    "    TS_copy = TS_norm_full.copy(deep= True)\n",
    "    history_predictions = pd.Series(index= daily_time_stamps)\n",
    "    history_reference = pd.Series(index= daily_time_stamps)\n",
    "    for i in np.arange(0,len(daily_time_stamps)):\n",
    "        time_stamp = daily_time_stamps[i]\n",
    "        index_time_stamp = TS_copy.index.get_loc(time_stamp) # want to predict the time_stamp\n",
    "        start = index_time_stamp - lag_value\n",
    "        end = index_time_stamp\n",
    "        history = TS[start:end+1]\n",
    "        prediction_input, reference = input_output_LSTM(history, temperature_norm, lag_value)\n",
    "        y_hat = model.predict(prediction_input)\n",
    "        # integrate the prediction in the TS_copy to be used in the next iterate\n",
    "        TS_copy[time_stamp] = y_hat\n",
    "        history_predictions[i] = y_hat\n",
    "        history_reference[i] = reference\n",
    "\n",
    "    return history_predictions, history_reference\n",
    "\n",
    "# print(time_step_prediction(model = trained_model, TS = TS, temperature_norm= temperature_norm, lag_value= 3, daily_time_stamps= pd.date_range(start=pd.Time)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "def get_all_days_of_year(serie: pd.Series)->set:\n",
    "    collection = set()\n",
    "    for date in serie.index:\n",
    "        collection.add(date.dayofyear)\n",
    "    return collection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "def test_set_prediction(model: Sequential, TS_norm_full: pd.Series, temperature_norm: pd.Series, lag_value: int, test_set:pd.Series):\n",
    "    # assumption that the test set has no gaps in the dates is not valid\n",
    "    collection = list(get_all_days_of_year(test_set))\n",
    "    day_int = collection[0]\n",
    "    daily_time_stamps = test_set[test_set.index.dayofyear == day_int].index\n",
    "    (history_predictions, history_reference) = daily_prediction(model, TS_norm_full, temperature_norm, lag_value, daily_time_stamps)\n",
    "    all_predictions = history_predictions\n",
    "    all_references = history_reference\n",
    "\n",
    "    if len(collection) > 1:\n",
    "        for day_int in collection[1:]:\n",
    "            daily_time_stamps = test_set[test_set.index.dayofyear == day_int].index\n",
    "            (history_predictions, history_reference) = daily_prediction(model, TS_norm_full, temperature_norm, lag_value, daily_time_stamps)\n",
    "            print(history_predictions)\n",
    "            all_predictions.append(history_predictions)\n",
    "            all_references.append(history_reference)\n",
    "\n",
    "    return all_predictions, all_references"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "2017-01-10 00:00:00    0.046831\n",
      "2017-01-10 00:30:00    0.033651\n",
      "2017-01-10 01:00:00    0.044027\n",
      "2017-01-10 01:30:00    0.038418\n",
      "2017-01-10 02:00:00    0.038979\n",
      "2017-01-10 02:30:00    0.043746\n",
      "2017-01-10 03:00:00    0.033932\n",
      "2017-01-10 03:30:00    0.045149\n",
      "2017-01-10 04:00:00    0.037016\n",
      "2017-01-10 04:30:00    0.077958\n",
      "2017-01-10 05:00:00    0.049916\n",
      "2017-01-10 05:30:00    0.038979\n",
      "2017-01-10 06:00:00    0.040662\n",
      "2017-01-10 06:30:00    0.043186\n",
      "2017-01-10 07:00:00    0.036175\n",
      "2017-01-10 07:30:00    0.048233\n",
      "2017-01-10 08:00:00    0.031127\n",
      "2017-01-10 08:30:00    0.048514\n",
      "2017-01-10 09:00:00    0.033371\n",
      "2017-01-10 09:30:00    0.088615\n",
      "2017-01-10 10:00:00    0.046270\n",
      "2017-01-10 10:30:00    0.050196\n",
      "2017-01-10 11:00:00    0.040381\n",
      "2017-01-10 11:30:00    0.049635\n",
      "2017-01-10 12:00:00    0.047672\n",
      "2017-01-10 12:30:00    0.057487\n",
      "2017-01-10 13:00:00    0.126472\n",
      "2017-01-10 13:30:00    0.042905\n",
      "2017-01-10 14:00:00    0.060292\n",
      "2017-01-10 14:30:00    0.119181\n",
      "2017-01-10 15:00:00    0.062535\n",
      "2017-01-10 15:30:00    0.194055\n",
      "2017-01-10 16:00:00    0.292204\n",
      "2017-01-10 16:30:00    0.243971\n",
      "2017-01-10 17:00:00    0.404375\n",
      "2017-01-10 17:30:00    0.305945\n",
      "2017-01-10 18:00:00    0.097588\n",
      "2017-01-10 18:30:00    0.323331\n",
      "2017-01-10 19:00:00    0.450365\n",
      "2017-01-10 19:30:00    0.137970\n",
      "2017-01-10 20:00:00    0.356702\n",
      "2017-01-10 20:30:00    0.050477\n",
      "2017-01-10 21:00:00    0.053001\n",
      "2017-01-10 21:30:00    0.053561\n",
      "2017-01-10 22:00:00    0.036736\n",
      "2017-01-10 22:30:00    0.042625\n",
      "2017-01-10 23:00:00    0.038138\n",
      "2017-01-10 23:30:00    0.038699\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(TS_norm[432:480])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stijn\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \"\"\"\n",
      "C:\\Users\\Stijn\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \n",
      "C:\\Users\\Stijn\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \"\"\"\n",
      "C:\\Users\\Stijn\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "2017-01-11 00:00:00         NaN\n",
      "2017-01-11 00:30:00         NaN\n",
      "2017-01-11 01:00:00         NaN\n",
      "2017-01-11 01:30:00    0.049439\n",
      "2017-01-11 02:00:00    0.049156\n",
      "2017-01-11 02:30:00    0.049507\n",
      "2017-01-11 03:00:00    0.049223\n",
      "2017-01-11 03:30:00    0.051070\n",
      "2017-01-11 04:00:00    0.054907\n",
      "2017-01-11 04:30:00    0.067554\n",
      "2017-01-11 05:00:00    0.067499\n",
      "2017-01-11 05:30:00    0.065647\n",
      "2017-01-11 06:00:00    0.058311\n",
      "2017-01-11 06:30:00    0.058676\n",
      "2017-01-11 07:00:00    0.063269\n",
      "2017-01-11 07:30:00    0.093215\n",
      "2017-01-11 08:00:00    0.112054\n",
      "2017-01-11 08:30:00    0.105178\n",
      "2017-01-11 09:00:00    0.088045\n",
      "2017-01-11 09:30:00    0.074878\n",
      "2017-01-11 10:00:00    0.088451\n",
      "2017-01-11 10:30:00    0.103925\n",
      "2017-01-11 11:00:00    0.114302\n",
      "2017-01-11 11:30:00    0.095784\n",
      "2017-01-11 12:00:00    0.061012\n",
      "2017-01-11 12:30:00    0.061127\n",
      "2017-01-11 13:00:00    0.100282\n",
      "2017-01-11 13:30:00    0.130029\n",
      "2017-01-11 14:00:00    0.139801\n",
      "2017-01-11 14:30:00    0.112206\n",
      "2017-01-11 15:00:00    0.090084\n",
      "2017-01-11 15:30:00    0.119045\n",
      "2017-01-11 16:00:00    0.143586\n",
      "2017-01-11 16:30:00    0.146323\n",
      "2017-01-11 17:00:00    0.163537\n",
      "2017-01-11 17:30:00    0.200683\n",
      "2017-01-11 18:00:00    0.215282\n",
      "2017-01-11 18:30:00    0.222115\n",
      "2017-01-11 19:00:00    0.191424\n",
      "2017-01-11 19:30:00    0.163689\n",
      "2017-01-11 20:00:00    0.156531\n",
      "2017-01-11 20:30:00    0.139035\n",
      "2017-01-11 21:00:00    0.137762\n",
      "2017-01-11 21:30:00    0.109126\n",
      "2017-01-11 22:00:00    0.085284\n",
      "2017-01-11 22:30:00    0.061094\n",
      "2017-01-11 23:00:00    0.050360\n",
      "2017-01-11 23:30:00    0.053520\n",
      "dtype: float64\n",
      "all_predictions: date\n",
      "2017-01-09 00:00:00    0.063984\n",
      "2017-01-09 00:30:00    0.067113\n",
      "2017-01-09 01:00:00    0.071547\n",
      "2017-01-09 01:30:00    0.070599\n",
      "2017-01-09 02:00:00    0.068290\n",
      "2017-01-09 02:30:00    0.067326\n",
      "2017-01-09 03:00:00    0.067180\n",
      "2017-01-09 03:30:00    0.075175\n",
      "2017-01-09 04:00:00    0.078458\n",
      "2017-01-09 04:30:00    0.094030\n",
      "2017-01-09 05:00:00    0.091214\n",
      "2017-01-09 05:30:00    0.090269\n",
      "2017-01-09 06:00:00    0.077874\n",
      "2017-01-09 06:30:00    0.076573\n",
      "2017-01-09 07:00:00    0.075324\n",
      "2017-01-09 07:30:00    0.103749\n",
      "2017-01-09 08:00:00    0.126844\n",
      "2017-01-09 08:30:00    0.122550\n",
      "2017-01-09 09:00:00    0.106323\n",
      "2017-01-09 09:30:00    0.095340\n",
      "2017-01-09 10:00:00    0.110964\n",
      "2017-01-09 10:30:00    0.107488\n",
      "2017-01-09 11:00:00    0.114512\n",
      "2017-01-09 11:30:00    0.092280\n",
      "2017-01-09 12:00:00    0.084443\n",
      "2017-01-09 12:30:00    0.078106\n",
      "2017-01-09 13:00:00    0.098674\n",
      "2017-01-09 13:30:00    0.093801\n",
      "2017-01-09 14:00:00    0.093248\n",
      "2017-01-09 14:30:00    0.103572\n",
      "2017-01-09 15:00:00    0.118972\n",
      "2017-01-09 15:30:00    0.147220\n",
      "2017-01-09 16:00:00    0.165445\n",
      "2017-01-09 16:30:00    0.168982\n",
      "2017-01-09 17:00:00    0.188931\n",
      "2017-01-09 17:30:00    0.194928\n",
      "2017-01-09 18:00:00    0.193654\n",
      "2017-01-09 18:30:00    0.198218\n",
      "2017-01-09 19:00:00    0.224848\n",
      "2017-01-09 19:30:00    0.224044\n",
      "2017-01-09 20:00:00    0.210193\n",
      "2017-01-09 20:30:00    0.162943\n",
      "2017-01-09 21:00:00    0.136067\n",
      "2017-01-09 21:30:00    0.116677\n",
      "2017-01-09 22:00:00    0.098751\n",
      "2017-01-09 22:30:00    0.069875\n",
      "2017-01-09 23:00:00    0.060151\n",
      "2017-01-09 23:30:00    0.070240\n",
      "dtype: float64 \n",
      ".\n",
      "all_references: date\n",
      "2017-01-09 00:00:00    0.183\n",
      "2017-01-09 00:30:00    0.201\n",
      "2017-01-09 01:00:00    0.225\n",
      "2017-01-09 01:30:00    0.221\n",
      "2017-01-09 02:00:00    0.226\n",
      "2017-01-09 02:30:00    0.222\n",
      "2017-01-09 03:00:00    0.323\n",
      "2017-01-09 03:30:00    0.126\n",
      "2017-01-09 04:00:00    0.137\n",
      "2017-01-09 04:30:00    0.108\n",
      "2017-01-09 05:00:00    0.136\n",
      "2017-01-09 05:30:00    0.113\n",
      "2017-01-09 06:00:00    0.123\n",
      "2017-01-09 06:30:00    0.105\n",
      "2017-01-09 07:00:00    0.105\n",
      "2017-01-09 07:30:00    0.111\n",
      "2017-01-09 08:00:00    0.098\n",
      "2017-01-09 08:30:00    0.117\n",
      "2017-01-09 09:00:00    0.106\n",
      "2017-01-09 09:30:00    0.110\n",
      "2017-01-09 10:00:00    0.101\n",
      "2017-01-09 10:30:00    0.118\n",
      "2017-01-09 11:00:00    0.094\n",
      "2017-01-09 11:30:00    0.254\n",
      "2017-01-09 12:00:00    0.133\n",
      "2017-01-09 12:30:00    0.156\n",
      "2017-01-09 13:00:00    0.148\n",
      "2017-01-09 13:30:00    0.153\n",
      "2017-01-09 14:00:00    0.241\n",
      "2017-01-09 14:30:00    0.208\n",
      "2017-01-09 15:00:00    0.199\n",
      "2017-01-09 15:30:00    0.211\n",
      "2017-01-09 16:00:00    0.236\n",
      "2017-01-09 16:30:00    0.138\n",
      "2017-01-09 17:00:00    0.154\n",
      "2017-01-09 17:30:00    0.110\n",
      "2017-01-09 18:00:00    0.159\n",
      "2017-01-09 18:30:00    1.035\n",
      "2017-01-09 19:00:00    0.684\n",
      "2017-01-09 19:30:00    0.376\n",
      "2017-01-09 20:00:00    0.230\n",
      "2017-01-09 20:30:00    0.101\n",
      "2017-01-09 21:00:00    0.133\n",
      "2017-01-09 21:30:00    0.100\n",
      "2017-01-09 22:00:00    0.135\n",
      "2017-01-09 22:30:00    0.098\n",
      "2017-01-09 23:00:00    0.142\n",
      "2017-01-09 23:30:00    0.105\n",
      "dtype: float64 \n",
      ".\n"
     ]
    }
   ],
   "source": [
    "all_predictions, all_references = test_set_prediction(trained_model, TS_norm_full, temperature_norm, 3, test)\n",
    "print(\"all_predictions: %s \\n.\"%all_predictions)\n",
    "print(\"all_references: %s \\n.\"%all_references)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def show_forecast(all_predictions, all_references):\n",
    "    axis = figure_layout(figsize=(10,8),titel=\"\",xlabel=\"date\",ylabel=\"\")\n",
    "    labels = [\"True Future\", \"Model Prediction\"]\n",
    "    marker = [\".-\", \".-\"]\n",
    "    time_steps = list(range(-(plot_data[0].shape[0]), 0))\n",
    "    if delta:\n",
    "        future = delta\n",
    "    else:\n",
    "        future = 0\n",
    "\n",
    "    plt.title(title)\n",
    "    for i, val in enumerate(plot_data):\n",
    "        if i:\n",
    "            plt.plot(future, plot_data[i], marker[i], markersize=10, label=labels[i])\n",
    "        else:\n",
    "            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
    "    plt.legend()\n",
    "    plt.xlim([time_steps[0], (future + 5) * 2])\n",
    "    plt.xlabel(\"Time-Step\")\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "for x, y in dataset_val.take(5):\n",
    "    show_plot(\n",
    "        [x[0][:, 1].numpy(), y[0].numpy(), model.predict(x)[0]],\n",
    "        12,\n",
    "        \"Single Step Prediction\",\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stijn\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Stijn\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "2017-02-01   NaN\n2017-02-02   NaN\n2017-02-03   NaN\n2017-02-04   NaN\n2017-02-05   NaN\n2017-02-06   NaN\n2017-02-07   NaN\n2017-02-08   NaN\n2017-02-09   NaN\n2017-02-10   NaN\n2017-01-01   NaN\n2017-01-02   NaN\n2017-01-03   NaN\n2017-01-04   NaN\n2017-01-05   NaN\n2017-01-06   NaN\n2017-01-07   NaN\n2017-01-08   NaN\n2017-01-09   NaN\n2017-01-10   NaN\ndtype: float64"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serieA = pd.Series(index= pd.date_range(start= pd.Timestamp(\"2017-02-01\"), end= pd.Timestamp(\"2017-02-10\")), name= \"serieA\")\n",
    "serieB = pd.Series(index= pd.date_range(start= pd.Timestamp(\"2017-01-01\"), end= pd.Timestamp(\"2017-01-10\")), name= \"serieB\")\n",
    "serieA.append(serieB)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}