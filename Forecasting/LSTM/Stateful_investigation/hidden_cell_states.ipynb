{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of missing values: 0. \n",
      "\n",
      "amount of missing values: 0. \n",
      "\n",
      "amount of missing values: 0. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.callbacks import History\n",
    "from forecasting_functions import *\n",
    "\n",
    "# importing the data\n",
    "Stijn = True\n",
    "fullYearpath = None\n",
    "av_temperaturepath = None\n",
    "\n",
    "if Stijn:\n",
    "    fullYearpath = \"D:\\Onedrive\\Leuven\\Final project\\data\\Forecasting_writtendata\\FullYear.csv\"\n",
    "    av_temperaturepath = \"D:\\Onedrive\\Leuven\\Final project\\data\\weather-avg.csv\"\n",
    "else:\n",
    "    raise Exception(\"Put some paths here.\")\n",
    "fullYeardata = pd.read_csv(fullYearpath,index_col= \"date\",parse_dates= True)\n",
    "av_temperature = pd.read_csv(av_temperaturepath,index_col='meter_id')\n",
    "av_temperature = av_temperature.transpose()\n",
    "av_temperature.index = pd.to_datetime(av_temperature.index)\n",
    "\n",
    "\n",
    "\n",
    "name = fullYeardata.columns[1]\n",
    "TS = fullYeardata[name]\n",
    "temperature = av_temperature[name]\n",
    "\n",
    "\n",
    "\n",
    "# all the training dates are present, dates from the test set can be missing.\n",
    "\n",
    "# normalize the data --> min/max method (when using a single time serie)\n",
    "temperature_norm,scaler_temperature = norm_forcast(temperature)\n",
    "temperature_norm = substitute_missing_values_temperature(temperature_norm)\n",
    "TS_norm,scaler_history = norm_forcast(TS)\n",
    "temp = TS_norm[TS_norm.index.month == 1]\n",
    "# temp = TS_norm[TS_norm.index.month != 12]\n",
    "# test = TS_norm[TS_norm.index.month == 12]\n",
    "\n",
    "# remove from the test set all the days that contain nan values -> only estimate real days\n",
    "# test.dropna(inplace=True)\n",
    "\n",
    "# substitute the missing values\n",
    "temp = substitute_missing_values(temp)\n",
    "training = temp[0:336]\n",
    "validation = temp[336:384]\n",
    "test = temp[384:528]\n",
    "# training = temp[temp.index.month != 11]\n",
    "# validation = temp[temp.index.month == 11]\n",
    "TS_norm_full = substitute_missing_values(TS_norm.copy(deep=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "(333, 3, 59)"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y = input_output_LSTM(training, temperature_norm, 3)\n",
    "X_val, y_val = input_output_LSTM(validation, temperature_norm, 3)\n",
    "X.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.]], dtype=float32), array([[0.]], dtype=float32), array([[0.]], dtype=float32)]\n",
      "----------\n",
      "[array([[0.09549879]], dtype=float32), array([[0.09549879]], dtype=float32), array([[0.19883052]], dtype=float32)]\n",
      "----------\n",
      "[array([[0.01529508]], dtype=float32), array([[0.01529508]], dtype=float32), array([[0.03055247]], dtype=float32)]\n",
      "----------\n",
      "[array([[0.00229115]], dtype=float32), array([[0.00229115]], dtype=float32), array([[0.00458128]], dtype=float32)]\n",
      "----------\n",
      "[array([[0.19473065]], dtype=float32), array([[0.19473065]], dtype=float32), array([[0.43662012]], dtype=float32)]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from numpy import array\n",
    "# define model\n",
    "inputs1 = Input(batch_shape=(1,3, 1))\n",
    "lstm1, state_h, state_c = LSTM(1, stateful= True, return_state= True)(inputs1)\n",
    "model = Model(inputs=inputs1, outputs=[lstm1, state_h, state_c])\n",
    "# define input data\n",
    "data = array([[0,0,0], [0.1, 0.2, 0.3],[0,0,0],[0,0,0],[0.6,0.3,0.6]])\n",
    "# make and show prediction\n",
    "for row in data:\n",
    "    row = row.reshape(1,3,1)\n",
    "    print(model.predict(row))\n",
    "    # model.reset_states()\n",
    "    print(10*'-')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.        ],\n",
      "       [0.14619657],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       [0.3154364 ]], dtype=float32), array([[0.        ],\n",
      "       [0.14619657],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       [0.3154364 ]], dtype=float32), array([[0.        ],\n",
      "       [0.26257628],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       [0.53567994]], dtype=float32)]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from numpy import array\n",
    "# define model\n",
    "inputs1 = Input(shape=(3, 1))\n",
    "lstm1, state_h, state_c = LSTM(1, return_state= True)(inputs1)\n",
    "model = Model(inputs=inputs1, outputs=[lstm1, state_h, state_c])\n",
    "# define input data\n",
    "data = array([[0,0,0], [0.1, 0.2, 0.3],[0,0,0],[0,0,0],[0.6,0.3,0.6]])\n",
    "data = data.reshape((5,3,1))\n",
    "# make and show prediction\n",
    "# for row in data:\n",
    "#     row = row.reshape(1,3,1)\n",
    "output = model.predict(data)\n",
    "print(model.predict(data))\n",
    "print(10*'-')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.05716937]], dtype=float32), array([[0.05716937]], dtype=float32), array([[0.11988591]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from numpy import array\n",
    "\n",
    "# define model\n",
    "inputs1 = Input(shape=(3, 1))\n",
    "lstm1, state_h, state_c = LSTM(1, return_state=True)(inputs1)\n",
    "model = Model(inputs=inputs1, outputs=[lstm1, state_h, state_c])\n",
    "# define input data\n",
    "data = array([0.1, 0.2, 0.3]).reshape((1,3,1))\n",
    "# make and show prediction\n",
    "print(model.predict(data))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input() got an unexpected keyword argument 'input_shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-7-1b47e69c2886>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0marray\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;31m# define model\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m \u001B[0minputs1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mInput\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_shape\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m \u001B[0mlstm1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mLSTM\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstateful\u001B[0m\u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mModel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minputs1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlstm1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: Input() got an unexpected keyword argument 'input_shape'"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from numpy import array\n",
    "# define model\n",
    "inputs1 = Input(shape=(3, 1))\n",
    "lstm1 = LSTM(1, stateful= False)(inputs1)\n",
    "model = Model(inputs=inputs1, outputs=lstm1)\n",
    "# define input data\n",
    "data = array([[0,0,0], [0.1, 0.2, 0.3],[0,0,0],[0,0,0],[0.6,0.3,0.6]])\n",
    "# make and show prediction\n",
    "# for row in data:\n",
    "#     row = row.reshape(5,3,1)\n",
    "print(model.predict(data.reshape((5,3,1)), batch_size= 5))\n",
    "# model.reset_states()\n",
    "print(10*'-')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        ]\n",
      " [0.0141051 ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.03010445]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from numpy import array\n",
    "data = array([[0,0,0], [0.1, 0.2, 0.3],[0,0,0],[0,0,0],[0.6,0.3,0.6]])\n",
    "model = Sequential()\n",
    "model.add(LSTM(1, batch_input_shape=(5,3,1)))\n",
    "\n",
    "# for row in data:\n",
    "#     row = row.reshape(1,3,1)\n",
    "#     print(model.predict(row))\n",
    "#     # model.reset_states()\n",
    "#     print(10*'-')\n",
    "\n",
    "data = data.reshape((5,3,1))\n",
    "print(model.predict(data, batch_size= 5))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333 45\n",
      "Train on 333 samples, validate on 45 samples\n",
      "Epoch 1/3\n",
      "232/333 [===================>..........] - ETA: 0s - loss: 0.1265 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [8,1] vs. [5,1]\n\t [[{{node training_29/Adam/gradients/loss_33/lstm_47_loss/mean_squared_error/sub_grad/BroadcastGradientArgs}}]]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-158-b4a2c4edc448>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     25\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 27\u001B[1;33m \u001B[0mtrained_model\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbuild_model_stateless1\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtraining\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtemperature_norm\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mverbose_para\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     28\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-158-b4a2c4edc448>\u001B[0m in \u001B[0;36mbuild_model_stateless1\u001B[1;34m(training, validation, temperature_norm, lag_value, nb_epoch, regularization_parameter, batch_size_para, verbose_para, save)\u001B[0m\n\u001B[0;32m     20\u001B[0m     \u001B[0mearly_stopping_monitor\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mEarlyStopping\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpatience\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mrestore_best_weights\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m     \u001B[1;31m# shuffle false --> not shuffle the training data\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 22\u001B[1;33m     \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_val\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my_val\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnb_epoch\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mshuffle\u001B[0m\u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m8\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mcallbacks\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mearly_stopping_monitor\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mhistory\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mverbose_para\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     23\u001B[0m     \u001B[1;31m# save the trained_model\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\ProgrammaX100\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001B[0m\n\u001B[0;32m   1237\u001B[0m                                         \u001B[0msteps_per_epoch\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msteps_per_epoch\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1238\u001B[0m                                         \u001B[0mvalidation_steps\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mvalidation_steps\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1239\u001B[1;33m                                         validation_freq=validation_freq)\n\u001B[0m\u001B[0;32m   1240\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1241\u001B[0m     def evaluate(self,\n",
      "\u001B[1;32mD:\\ProgrammaX100\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001B[0m in \u001B[0;36mfit_loop\u001B[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001B[0m\n\u001B[0;32m    194\u001B[0m                     \u001B[0mins_batch\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mins_batch\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtoarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    195\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 196\u001B[1;33m                 \u001B[0mouts\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfit_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mins_batch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    197\u001B[0m                 \u001B[0mouts\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mto_list\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mouts\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    198\u001B[0m                 \u001B[1;32mfor\u001B[0m \u001B[0ml\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mo\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout_labels\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mouts\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\ProgrammaX100\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m   3290\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3291\u001B[0m     fetched = self._callable_fn(*array_vals,\n\u001B[1;32m-> 3292\u001B[1;33m                                 run_metadata=self.run_metadata)\n\u001B[0m\u001B[0;32m   3293\u001B[0m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call_fetch_callbacks\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfetched\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_fetches\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3294\u001B[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001B[1;32mD:\\ProgrammaX100\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1456\u001B[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001B[0;32m   1457\u001B[0m                                                \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_handle\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1458\u001B[1;33m                                                run_metadata_ptr)\n\u001B[0m\u001B[0;32m   1459\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mrun_metadata\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1460\u001B[0m           \u001B[0mproto_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf_session\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTF_GetBuffer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrun_metadata_ptr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: Incompatible shapes: [8,1] vs. [5,1]\n\t [[{{node training_29/Adam/gradients/loss_33/lstm_47_loss/mean_squared_error/sub_grad/BroadcastGradientArgs}}]]"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense,  LSTM,Embedding\n",
    "from keras.models import Sequential, save_model, load_model\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint, History\n",
    "\n",
    "def build_model_stateless1(training: pd.Series,validation: pd.Series, temperature_norm: pd.Series, lag_value: int,nb_epoch: int = 1, regularization_parameter: float = 0.01,batch_size_para: int = 32,verbose_para: int = 1, save: bool = False):\n",
    "    history = History()\n",
    "    X,y = input_output_LSTM(training, temperature_norm, lag_value)\n",
    "    X_val,y_val = input_output_LSTM(validation, temperature_norm, lag_value)\n",
    "    print(len(X), len(X_val))\n",
    "    regularizers.l2(l=regularization_parameter)\n",
    "    model = Sequential()\n",
    "    # no initial state is given --> hidden state are tensors filled with zeros\n",
    "    # dropout=None,recurrent_dropout=None\n",
    "    model.add(LSTM(units=1,activation='tanh',stateful= False, batch_input_shape=(8,X.shape[1],X.shape[2])))\n",
    "    # model.add(Dense(units=20,activation='relu',kernel_regularizer='l2'))\n",
    "    # model.add(Dropout(0.10))\n",
    "    # model.add(Dense(units=y.shape[1],activation='relu',kernel_regularizer='l2'))\n",
    "    model.compile(optimizer='adam',loss='mse')\n",
    "    early_stopping_monitor = EarlyStopping(patience=5,restore_best_weights=True)\n",
    "    # shuffle false --> not shuffle the training data\n",
    "    model.fit(x=X,y=y,validation_data=(X_val,y_val), epochs=nb_epoch,shuffle= False, batch_size=8,callbacks=[early_stopping_monitor,history],verbose=verbose_para)\n",
    "    # save the trained_model\n",
    "\n",
    "    return model\n",
    "\n",
    "trained_model = build_model_stateless1(training, validation,temperature_norm,3,3,verbose_para=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 59)\n",
      "[[0.07492943]\n",
      " [0.1329707 ]\n",
      " [0.05895755]]\n"
     ]
    }
   ],
   "source": [
    "X_pred = X\n",
    "X_pred = np.insert(X_pred,0,0,axis=0)\n",
    "X_pred = np.insert(X_pred,2,0,axis=0)\n",
    "X_pred = np.insert(X_pred,-1,0,axis=0)\n",
    "# trained_model.reset_states()\n",
    "# for i in range(len(X_pred)):\n",
    "#     row = X_pred[i,:,:]\n",
    "#     row = np.expand_dims(row,axis=0)\n",
    "#     print(trained_model.predict(row, batch_size= 2))\n",
    "print(X_pred[0:3].shape)\n",
    "print(trained_model.predict(X_pred[0:3], batch_size= 3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}